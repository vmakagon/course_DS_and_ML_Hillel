{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"01 RNN_IMDB_.ipynb","version":"0.3.2","provenance":[{"file_id":"1cI8oab4pkKPAs5ePP8b4xTrddobh7Hgo","timestamp":1567689637824},{"file_id":"1zG1MtRdSjI5rrjsT_JLDo6FdN4u2Scfx","timestamp":1565717135659}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"r8h5jg1qZTkW","colab_type":"text"},"source":["RNN sentiment analysis\n","Это код на Keras, который использует простую rnn для задачи sentiment analysis текстов длиной до 80 символов, используя 20,000 самых частых английских слов. Точность на 10ти эпохах при простейшей конфигурации - 70%\n","\n","\n","Необходимо \"прочитать\" код и воплнить следующие задания:\n","\n","1) Добавить еще один слой SimpleRNN (128 нейронов) и протестировать точность и скорость\n","\n","2) Заменить SimpleRNN на LSTM в однослойной и двухслойной моделях, протестировать точность и скорость\n","\n","\n","\n","https://colab.research.google.com/drive/1zG1MtRdSjI5rrjsT_JLDo6FdN4u2Scfx\n","\n","\n","\n","P.S. Мы еще будем более подробно рассматривать устройство RNN в целом, и LSTM в частности. Это задание скорее на понимание скорости и точности разных моделей рекуррентных сетей."]},{"cell_type":"code","metadata":{"id":"sEyzw1A2yg7L","colab_type":"code","outputId":"ab5d15fe-775a-4c98-a232-1fcd8db5b8ec","executionInfo":{"status":"ok","timestamp":1567690606646,"user_tz":-180,"elapsed":630675,"user":{"displayName":"Виталий Макагон","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBe3uupfRUxTT-UfGNBWIZgGrid6kaXefxy107DeQ=s64","userId":"11957033386173939152"}},"colab":{"base_uri":"https://localhost:8080/","height":672}},"source":["from __future__ import print_function\n","\n","import keras\n","from keras.preprocessing import sequence\n","from keras.models import Sequential\n","from keras.layers import Dense, Embedding\n","from keras.layers import SimpleRNN # --> from keras.layers import LSTM\n","from keras.datasets import imdb\n","\n","\n","max_features = 20000\n","# cut texts after this number of words (among top max_features most common words)\n","maxlen = 80\n","batch_size = 32\n","\n","\n","import numpy as np\n","\n","np.load.__defaults__=(None, True, True, 'ASCII')\n","\n","(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n","\n","#print('Loading data...')\n","#(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n","print(len(x_train), 'train sequences')\n","print(len(x_test), 'test sequences')\n","\n","print('Pad sequences (samples x time)')\n","x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n","x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n","print('x_train shape:', x_train.shape)\n","print('x_test shape:', x_test.shape)\n","\n","print('Build model...')\n","model = Sequential()\n","model.add(Embedding(max_features, 128))\n","model.add(SimpleRNN(64, dropout=0.2, recurrent_dropout=0.2, return_sequences=True)) # --> model.add(LSTM(...\n","model.add(SimpleRNN(128, dropout=0.2, recurrent_dropout=0.2))\n","model.add(Dense(1, activation='sigmoid'))\n","\n","# try using different optimizers and different optimizer configs\n","model.compile(loss='binary_crossentropy',\n","              optimizer='adam',\n","              metrics=['accuracy'])\n","\n","print('Train...')\n","model.fit(x_train, y_train,\n","          batch_size=batch_size,\n","          epochs=10,\n","          validation_data=(x_test, y_test))\n","score, acc = model.evaluate(x_test, y_test,\n","                            batch_size=batch_size)\n","print('Test score:', score)\n","print('Test accuracy:', acc)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["25000 train sequences\n","25000 test sequences\n","Pad sequences (samples x time)\n","x_train shape: (25000, 80)\n","x_test shape: (25000, 80)\n","Build model...\n"],"name":"stdout"},{"output_type":"stream","text":["W0905 13:26:22.227504 139623716452224 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n","W0905 13:26:22.244313 139623716452224 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n","W0905 13:26:22.249265 139623716452224 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n"],"name":"stderr"},{"output_type":"stream","text":["Train...\n","Train on 25000 samples, validate on 25000 samples\n","Epoch 1/10\n","25000/25000 [==============================] - 63s 3ms/step - loss: 0.7063 - acc: 0.5060 - val_loss: 0.6868 - val_acc: 0.5253\n","Epoch 2/10\n","25000/25000 [==============================] - 61s 2ms/step - loss: 0.6768 - acc: 0.5672 - val_loss: 0.6672 - val_acc: 0.5730\n","Epoch 3/10\n","25000/25000 [==============================] - 61s 2ms/step - loss: 0.6219 - acc: 0.6443 - val_loss: 0.6960 - val_acc: 0.5797\n","Epoch 4/10\n","25000/25000 [==============================] - 61s 2ms/step - loss: 0.5856 - acc: 0.6819 - val_loss: 0.6969 - val_acc: 0.5898\n","Epoch 5/10\n","25000/25000 [==============================] - 61s 2ms/step - loss: 0.5422 - acc: 0.7196 - val_loss: 0.6886 - val_acc: 0.6040\n","Epoch 6/10\n","25000/25000 [==============================] - 61s 2ms/step - loss: 0.5048 - acc: 0.7453 - val_loss: 0.7049 - val_acc: 0.6308\n","Epoch 7/10\n","25000/25000 [==============================] - 61s 2ms/step - loss: 0.4887 - acc: 0.7577 - val_loss: 0.7294 - val_acc: 0.6033\n","Epoch 8/10\n","25000/25000 [==============================] - 61s 2ms/step - loss: 0.4638 - acc: 0.7766 - val_loss: 0.7094 - val_acc: 0.6310\n","Epoch 9/10\n","25000/25000 [==============================] - 61s 2ms/step - loss: 0.4332 - acc: 0.7999 - val_loss: 0.6558 - val_acc: 0.6662\n","Epoch 10/10\n","25000/25000 [==============================] - 61s 2ms/step - loss: 0.4196 - acc: 0.8066 - val_loss: 0.6786 - val_acc: 0.6133\n","25000/25000 [==============================] - 11s 444us/step\n","Test score: 0.6786445868682861\n","Test accuracy: 0.61328\n"],"name":"stdout"}]}]}