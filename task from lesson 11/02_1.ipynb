{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"02_1 RNN_IMDB_.ipynb","version":"0.3.2","provenance":[{"file_id":"1JYOPhXRS96mg1WUG3T9ZISD0k4hbgI6q","timestamp":1567689774133},{"file_id":"1cI8oab4pkKPAs5ePP8b4xTrddobh7Hgo","timestamp":1567689637824},{"file_id":"1zG1MtRdSjI5rrjsT_JLDo6FdN4u2Scfx","timestamp":1565717135659}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"r8h5jg1qZTkW","colab_type":"text"},"source":["RNN sentiment analysis\n","Это код на Keras, который использует простую rnn для задачи sentiment analysis текстов длиной до 80 символов, используя 20,000 самых частых английских слов. Точность на 10ти эпохах при простейшей конфигурации - 70%\n","\n","\n","Необходимо \"прочитать\" код и воплнить следующие задания:\n","\n","1) Добавить еще один слой SimpleRNN (128 нейронов) и протестировать точность и скорость\n","\n","2) Заменить SimpleRNN на LSTM в однослойной и двухслойной моделях, протестировать точность и скорость\n","\n","\n","\n","https://colab.research.google.com/drive/1zG1MtRdSjI5rrjsT_JLDo6FdN4u2Scfx\n","\n","\n","\n","P.S. Мы еще будем более подробно рассматривать устройство RNN в целом, и LSTM в частности. Это задание скорее на понимание скорости и точности разных моделей рекуррентных сетей."]},{"cell_type":"code","metadata":{"id":"sEyzw1A2yg7L","colab_type":"code","outputId":"6c76abbb-5d4a-44a1-8722-3a9d5e64fcea","executionInfo":{"status":"ok","timestamp":1567692320810,"user_tz":-180,"elapsed":1262810,"user":{"displayName":"Виталий Макагон","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBe3uupfRUxTT-UfGNBWIZgGrid6kaXefxy107DeQ=s64","userId":"11957033386173939152"}},"colab":{"base_uri":"https://localhost:8080/","height":756}},"source":["from __future__ import print_function\n","\n","import keras\n","from keras.preprocessing import sequence\n","from keras.models import Sequential\n","from keras.layers import Dense, Embedding, LSTM\n","from keras.layers import SimpleRNN # --> from keras.layers import LSTM\n","from keras.datasets import imdb\n","\n","\n","max_features = 20000\n","# cut texts after this number of words (among top max_features most common words)\n","maxlen = 80\n","batch_size = 32\n","\n","\n","import numpy as np\n","\n","np.load.__defaults__=(None, True, True, 'ASCII')\n","\n","(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n","\n","#print('Loading data...')\n","#(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n","print(len(x_train), 'train sequences')\n","print(len(x_test), 'test sequences')\n","\n","print('Pad sequences (samples x time)')\n","x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n","x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n","print('x_train shape:', x_train.shape)\n","print('x_test shape:', x_test.shape)\n","\n","print('Build model...')\n","model = Sequential()\n","model.add(Embedding(max_features, 128))\n","model.add(LSTM(64, dropout=0.2, recurrent_dropout=0.2)) # --> model.add(LSTM(...\n","model.add(Dense(1, activation='sigmoid'))\n","\n","# try using different optimizers and different optimizer configs\n","model.compile(loss='binary_crossentropy',\n","              optimizer='adam',\n","              metrics=['accuracy'])\n","\n","print('Train...')\n","model.fit(x_train, y_train,\n","          batch_size=batch_size,\n","          epochs=10,\n","          validation_data=(x_test, y_test))\n","score, acc = model.evaluate(x_test, y_test,\n","                            batch_size=batch_size)\n","print('Test score:', score)\n","print('Test accuracy:', acc)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["25000 train sequences\n","25000 test sequences\n","Pad sequences (samples x time)\n"],"name":"stdout"},{"output_type":"stream","text":["W0905 13:44:23.993272 140134474487680 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n","\n","W0905 13:44:24.001867 140134474487680 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"],"name":"stderr"},{"output_type":"stream","text":["x_train shape: (25000, 80)\n","x_test shape: (25000, 80)\n","Build model...\n"],"name":"stdout"},{"output_type":"stream","text":["W0905 13:44:24.229453 140134474487680 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n","W0905 13:44:24.247027 140134474487680 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n","W0905 13:44:24.251880 140134474487680 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n"],"name":"stderr"},{"output_type":"stream","text":["Train...\n","Train on 25000 samples, validate on 25000 samples\n","Epoch 1/10\n","25000/25000 [==============================] - 125s 5ms/step - loss: 0.4562 - acc: 0.7852 - val_loss: 0.3761 - val_acc: 0.8348\n","Epoch 2/10\n","25000/25000 [==============================] - 124s 5ms/step - loss: 0.2986 - acc: 0.8781 - val_loss: 0.3851 - val_acc: 0.8256\n","Epoch 3/10\n","25000/25000 [==============================] - 124s 5ms/step - loss: 0.2188 - acc: 0.9153 - val_loss: 0.4601 - val_acc: 0.8204\n","Epoch 4/10\n","25000/25000 [==============================] - 123s 5ms/step - loss: 0.1534 - acc: 0.9437 - val_loss: 0.4541 - val_acc: 0.8261\n","Epoch 5/10\n","25000/25000 [==============================] - 123s 5ms/step - loss: 0.1142 - acc: 0.9578 - val_loss: 0.5439 - val_acc: 0.8277\n","Epoch 6/10\n","25000/25000 [==============================] - 123s 5ms/step - loss: 0.0812 - acc: 0.9716 - val_loss: 0.5748 - val_acc: 0.8212\n","Epoch 7/10\n","25000/25000 [==============================] - 122s 5ms/step - loss: 0.0600 - acc: 0.9803 - val_loss: 0.7021 - val_acc: 0.8190\n","Epoch 8/10\n","25000/25000 [==============================] - 123s 5ms/step - loss: 0.0532 - acc: 0.9815 - val_loss: 0.7189 - val_acc: 0.8188\n","Epoch 9/10\n","25000/25000 [==============================] - 123s 5ms/step - loss: 0.0336 - acc: 0.9891 - val_loss: 0.7935 - val_acc: 0.8171\n","Epoch 10/10\n","25000/25000 [==============================] - 122s 5ms/step - loss: 0.0268 - acc: 0.9920 - val_loss: 0.9292 - val_acc: 0.8121\n","25000/25000 [==============================] - 23s 930us/step\n","Test score: 0.9291922618147731\n","Test accuracy: 0.81208\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rtCS7FM8lyIc","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}